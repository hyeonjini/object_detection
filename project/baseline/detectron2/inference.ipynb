{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9614999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b14f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try:\n",
    "    register_coco_instances('trash_test', {}, '../dataset/test.json', '../dataset/')\n",
    "except AssertionError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7ad5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('faster_rcnn_R_101_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2259060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "cfg.DATASETS.TEST = ('trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 2\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, 'model_0009999.pth')\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e6aa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/09 15:37:18 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[10/09 15:37:18 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../dataset/test.json\n",
      "\u001b[32m[10/09 15:37:18 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/09 15:37:18 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/09 15:37:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.50 MiB\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# mapper - input data를 어떤 형식으로 return할지\n",
    "def MyMapper(dataset_dict):\n",
    "    \n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    dataset_dict['image'] = image\n",
    "    \n",
    "    return dataset_dict\n",
    "\n",
    "# test loader\n",
    "test_loader = build_detection_test_loader(cfg, 'trash_test', MyMapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da993da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4871 [00:00<?, ?it/s]/opt/ml/detection/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:154: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370156314/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  filter_inds = filter_mask.nonzero()\n",
      "100%|██████████| 4871/4871 [05:44<00:00, 14.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7 0.9992503523826599 221.61992 60.28158 455.74...</td>\n",
       "      <td>test/0000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 0.9692215919494629 123.993355 6.259248 501.1...</td>\n",
       "      <td>test/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 0.9994056224822998 424.00546 267.73508 646.5...</td>\n",
       "      <td>test/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9 0.9963656663894653 131.89699 288.0879 892.64...</td>\n",
       "      <td>test/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 0.9969171285629272 213.44302 333.98788 867.0...</td>\n",
       "      <td>test/0004.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    PredictionString       image_id\n",
       "0  7 0.9992503523826599 221.61992 60.28158 455.74...  test/0000.jpg\n",
       "1  5 0.9692215919494629 123.993355 6.259248 501.1...  test/0001.jpg\n",
       "2  1 0.9994056224822998 424.00546 267.73508 646.5...  test/0002.jpg\n",
       "3  9 0.9963656663894653 131.89699 288.0879 892.64...  test/0003.jpg\n",
       "4  0 0.9969171285629272 213.44302 333.98788 867.0...  test/0004.jpg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output 뽑은 후 sumbmission 양식에 맞게 후처리 \n",
    "prediction_strings = []\n",
    "file_names = []\n",
    "\n",
    "class_num = 10\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    \n",
    "    prediction_string = ''\n",
    "    \n",
    "    data = data[0]\n",
    "    \n",
    "    outputs = predictor(data['image'])['instances']\n",
    "    \n",
    "    targets = outputs.pred_classes.cpu().tolist()\n",
    "    boxes = [i.cpu().detach().numpy() for i in outputs.pred_boxes]\n",
    "    scores = outputs.scores.cpu().tolist()\n",
    "    \n",
    "    for target, box, score in zip(targets,boxes,scores):\n",
    "        prediction_string += (str(target) + ' ' + str(score) + ' ' + str(box[0]) + ' ' \n",
    "        + str(box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' ')\n",
    "        \n",
    "    prediction_strings.append(prediction_string)\n",
    "    file_names.append(data['file_name'].replace('../dataset/',''))\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['PredictionString'] = prediction_strings\n",
    "submission['image_id'] = file_names\n",
    "submission.to_csv(os.path.join(cfg.OUTPUT_DIR, f'submission_det2.csv'), index=None)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b1c326-39f2-4587-9d33-94ed36d4c94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
